% ! TeX root = ../../thesis.tex
\chapter{Contesto e motivazioni}
\label{chapter:context-and-motivations}

\todo{introduzione}

\section{Il problema del plagio nel software}

\todo{definisce il problema, eventuali sottocapitoli che spiegano come è diviso}

\section{Sistemi antiplagio automatici}

\todo{spiegare cosa esiste e perché serve che sia automatico}

\section{Stato dell'arte}
% preso spunto da "Current trends in source code analysis, plagiarism detection and issues of analysis big datasets" -- si deve citare??
Il codice sorgente non è nient'altro che un file di testo scritto da sviluppatori, che deve essere compilato o interpretato e che, pertanto, si basa su regole sintattiche e grammaticali proprie del linguaggio di programmazione con cui è scritto che permettono a entrambi gli attori, il programmatore e il calcolatore, di "capirlo" ed elaborarlo.

Per questo motivo, se processare la struttura di un sorgente non presenta grandi difficoltà, processare il significato, ovvero l'idea e la logica sottesa al codice, costituisce una sfida più grande, se non altro perché entra in gioco la competenza dello sviluppatore e la sua esperienza nella scrittura di codice "pulito".

Poiché il problema è complesso, gli attuali metodi di analisi non aspirano a risolvere il problema \textit{in toto}, ma analizzano il codice sorgente utilizzando particolare "punto di vista": alcuni analizzano il codice dal punto di vista del programmatore, cercando di comprenderne il significato, altri la loro struttura.

% Possiamo classificare le tecniche di analisi in tre approcci: 

% Il primo si basa sull'analisi del codice come mero testo: si presume che siano rispettate le convenzioni e il codice contenga sufficienti informazioni che ne descrivano il significato e cercano di estrarre solo queste significative informazioni aggiuntive.

% Il livello successivo è simile al precedente con la differenza che non esplora il significato del testo dal punto di vista del programmatore, bensì dal punto di vista del calcolatore, che "vede" il codice come una sequenza di comandi, ciascuno con il proprio significato nel contesto della grammatica del linguaggio.

% L'ultimo e terzo livello riguarda l'analisi del modello del codice sorgente.

In generale, come già accennato nel \todo{ref?}, la maggior parte dei sistemi automatici d'identificazione di plagi lavorano in due fasi consecutive: prima il codice sorgente viene analizzato e viene generata una rappresentenzazione intermedia, poi si effettua il confronto dei sorgenti sulle rappresentazioni intermedie.

Le tecniche di analisi possono essere classificate in tre cataegorie: \textbf{\textit{structure-based}}, \textbf{\textit{attribute-based}}, \textbf{\textit{hybrid detection}}. \todo{citazione?}

\subsection{Analisi \textit{structure-based}}

\subsubsection{Analisi lessicale}
Tra tutte, la tecnica più usata consiste nell'analisi lessicale (\textbf{\textit{lexical analysis}} o \textbf{\textit{tokenization}} in inglese) del codice sorgente, che consiste nel convertire la sequenza di caratteri di cui è composto il programma in una sequenza di \textit{token}.
%
Un \textit{token} è una sequenza di caratteri che costituisce un'unità fondamentale nella grammatica del linguaggio ed è strutturato come una coppia \textit{nome} - \textit{valore}.
%
Alcuni possibili esempi sono riportati in \Cref{table:token-examples}.

\begin{itemize}
    \item \textit{identifier}: una stringa di lettere e numeri che iniziano con una lettera (usato per rappresentare i nomi scelti dai programmatori);
    \item \textit{keyword}: stringa per rappresentare i nomi dedicati nella sintassi del linguaggio;
    \item \textit{separator}: caratteri delimitatori e di punteggiatura;
    \item \textit{comment}: blocco di commenti.
\end{itemize}

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|} 
        \hline
        \textbf{Nome} & \textbf{Esempi di valori} \\ [0.5ex] 
        \hline\hline
        \textit{identifier} & \texttt{x}, \texttt{name}, \texttt{color} \\ 
        \hline
        \textit{keyword} & \texttt{if}, \texttt{for}, \texttt{return} \\
        \hline
        \textit{separator} & \texttt{\{}, \texttt{\}}, \texttt{(}, \texttt{;} \\
        \hline
        \textit{comment} & \texttt{/* This is a sample comment */} \\
        \hline
    \end{tabular}
    \caption{Esempi di possibili coppie nome-valore di \textit{token} comuni.}
    \label{table:token-examples}
\end{table}

L'analisi lessicale rappresenta il primo stadio della struttura di un compilatore ed è eseguita da programmi denominati \textbf{\textit{lexer}}. 
%
Questi sono generati in maniera dichiarativa a partire da generatori di \textit{lexer} (\textbf{\textit{lexer generator}}) che, presi in input più automa a stati finiti, espressi per mezzo di espressioni regolari che definiscono in maniera formale la grammatica del linguaggio, generano il codice che implementa l'algoritmo di analisi lessicale. 
% https://www.antlr.org ??

Attraverso questo approccio, quindi, ogni programma viene trasformato in una sequenza di \textit{token}, uno per ciascun elemento di base del linguaggio che si vuole valorizzare: i blocchi di commenti o documentazione, gli \texttt{import} e altre sezioni di codice non rilevanti ai fini della comparazione possono essere esclusi, cioè non viene generato alcun \textit{token} per questi elementi.
%
Questo li rende insensibili contro le modifiche ma \dots

\todo{esempio di tokenizzazione applicata a un sorgente}

In seguito, la sequenza di \textit{token} generata viene confrontata con algoritmi di \textit{string matching}.

\subsubsection{Analisi basata su un modello}
Invece di utilizzare la mera sequenza di \textit{token} generata dal generatore di \textit{lexer} possono essere generate delle strutture e dei modelli più complessi.

Il più diffuso è l'\textbf{albero sintattico} (o \textit{abstract syntax tree} in inglese, abbreviato AST).

\dots

Program Dependency Graph

\subsection{Analisi \textit{attribute-based}}
Nonostante l'efficienza delle tecniche di analisi strutturale descritte precedentemente, il loro punto debole si riscontra nelle prestazioni. 
%
Per far fronte a questo problema sono state storicamente introdotte nuove tecniche, dette \textit{attribute-based}, in quanto determinano il grado di similarità tra due sorgenti sulla base delle loro \dots

\subsection{\textit{Hybrid detection}}

\subsection{Quale tecnica scegliere?}
In conclusione, scegliere quali di questi approcci scegliere è complesso, perché difficili da confrontare tra loro: la maggior parte di queste tecniche viene valutata utilizzando il proprio \textit{set} di dati, che raramente sono resi pubblicamente accessibili \cite{karnalim-budi-toba-joy-2019}.

In conclusione, bisogna rendersi conto che, a prescindere dal grado di sofisticatezza della tecnica che si utilizza, è sempre possibile che si verifichi un plagio non rilevabile.
%
Da bilanciare le risorse investite nell'individuazione del plagio e i rendimenti decrescenti di trovare i pochi, se non nessuno, casi difficili da rilevare \cite{joy-99}.


