% ! TeX root = ../../thesis.tex
\chapter{Contesto e motivazioni}
\label{chapter:context-and-motivations}

Negli ultimi decenni, con la rapida crescita di dati e informazioni facilmente accessibili sul \textit{web}, è diventato sempre più semplice poter utilizzare, in parte o in tutto, le risorse reperite.
%
Tuttavia, l'uso improprio di tali risorse, senza attribuire i necessari crediti agli autori, costituisce, oltre che una pratica scorretta che contravviene a qualsiasi ordine deontologico, un illecito \cite{copyright-law-italia}.

In generale, l'atto di appropriarsi degli scritti di altre persone, in violazione della legge sul \textit{copyright}, viene definito \textbf{plagio} \cite{britannica}.

\section{Il problema del plagio nel software}
Anche nel mondo dell'informatica il problema del plagio è un fenomeno in crescita, incoraggiato per lo più dalla sempre maggiore quantità di progetti \textit{software} \textit{open source}, che induce gli sviluppatori a copia incollare frammenti di codice, talvolta neppure conoscendo le relative condizioni e termini di licenza.
%
Questo porta spesso a un uso improprio del codice altrui arrecando sanzioni e danni per lo sviluppatore.

\todo{definisce il problema, eventuali sottocapitoli che spiegano come è diviso}

\section{Sistemi antiplagio automatici}

\todo{Approccio manuale non fattibile}

Già a partire dagli anni settanta del novecento, sono stati proposti algoritmi e tecniche per l'analisi del codice, nonché l'identificazione e localizzazione di plagi.

In questo contesto è da porre in evidenza la differenza tra l'individuazione di cloni e quella di plagi.
%
Quando ci si riferisce a un clone, infatti, lo si fa con riferimento a un frammento di codice che è stata copiato e marginalmente modificato. 
%
Quando invece ci si riferisce ad un plagio si intende una sezione che è stata copiata e la cui opera di copiatura si è cercato di dissimulare, mediante opportune azioni di rifattorizzazione del codice \cite{muddu-et-al-2013}.  
%
Dunque, l'ambito di applicazione delle due ricerche è nettamente diverso: se nel primo l'obiettivo è quello di evidenziare il codice duplicato al fine di migliorare la qualità del codice e la manutenibilità del sistema, nel secondo lo scopo primario è identificare possibili condotte illecite.

Questo aspetto è, insieme alle prestazioni, la sfida principale da affrontare durante la progettazione di un sistema antiplagio.

\subsection{La rifattorizzazione del codice}
La capacità di un software antiplagio nel riuscire ad identificare possibili parti di codice plagiate, passa anche, e soprattutto, dall'abilità dello sviluppatore di saper rifattorizzare il codice.

In generale, non è possibile classificare tutti i possibili metodi con cui un programma può essere trasformato in un altro mantenendo inalterate le sue funzionalità.
%
Tuttavia, è possibile distinguere due macro categorie di modifiche: \textbf{lessicali} e \textbf{strutturali} \cite{joy-99}.

Le modifiche lessicali sono quelle che, in linea di principio, possono essere eseguite da un \textit{text editor} e non richiedono la conoscenza del linguaggio di programmazione con cui è stato sviluppato il codice. 
%
Alcuni casi esemplificativi sono:
\begin{itemize}
    \item la riformulazione di commenti, la loro aggiunta o rimozione;
    \item la riformattazione del testo, come l'introduzione di spazi vuoti, di nuove linee o il cambio dell'ordine dei parametri nella definizione delle funzioni;
    \item cambiare il nome degli identificatori e delle funzioni o i tipi di dato: ad esempio da \texttt{int} a \texttt{Integer} o da \texttt{float} a \texttt{double}.
\end{itemize}

Le modifiche strutturali sono invece fortemente dipendenti dal linguaggio di programmazione e richiedono un maggior sforzo in termini di comprensione della logica del codice.
%
Di seguito alcuni esempi di rifattorizzazioni che rientrano in questa classe:
\begin{itemize}
    \item aggiungere istruzioni ridondanti, come dichiarazioni, inizializzazioni, istruzioni di stampa;
    \item sostituire i costrutti di loop con costrutti equivalenti: passare, ad esempio, da \texttt{for} a \texttt{do/while}, o da un approccio iterativo a uno funzionale (ad esempio tramite l'uso degli \texttt{Stream} in Java);
    \item sostituire istruzioni \texttt{if} nidificate con dichiarazioni equivalenti, ad esempio \texttt{when} (in Kotlin) o \texttt{switch-case}, e viceversa;
    \item cambiare l'ordine di istruzioni indipendenti;
    \item cambiare l'ordine degli operandi: ad esempio \texttt{x < y} può essere cambiato in \texttt{y >= x};
    \item sostituire la chiamata a funzione con il corpo della stessa.
\end{itemize}

Gli strumenti d'identificazione di plagi devono pertanto cercare di annullare gli effetti di queste rifattorizzazioni.
%
A questo scopo le tecniche di analisi si compongono di più fasi nelle quali trasformano i sorgenti in rappresentazioni intermedie che astraggono il più possibile dai dettagli implementativi, che possono essere facilmente cambiati, quindi applicano su di esse tecniche di confronto.

Si osservi, tuttavia, che esistono rifattorizzazioni il cui contributo è più facile da annullare di altre. 
%
Si pensi, ad esempio, all'aggiunta o alla modifica dei commenti: l'effetto di tale rifattorizzazione è facilmente annullabile semplicemente trascurando dall'analisi i commenti, in quanto non contribuiscono in alcun modo alla logica del programma. 
%
D'altro canto, creare tecniche che siano insensibili al riordino delle istruzioni è un compito più complesso.

In \Cref{img:01-levels-of-plagiarism} viene riportata la tassonomia dei livelli di plagio di Faidhi \& Robinson definita in \cite{faidhi-robinson-1987} che mappa le possibili rifattorizzazioni in sette livelli o categorie, sulla base della loro difficoltà: il più semplice è il livello 0 che corrisponde a una copia letterale; il più impegnativo è il livello 6 che corrisponde a un cambiamento logico e può essere considerato plagio solo se si verifica in concomitanza con altri livelli.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{resources/img/01-levels-of-plagiarism.pdf}
    \caption{Tassonomia dei livelli di plagio di Faidhi \& Robinson (1987).}
    \label{img:01-levels-of-plagiarism}
\end{figure}

Maggiore sarà il livello di rifattorizazzione a cui il sistema antiplagio sarà insensibile, migliore sarà l'efficacia e la robustezza del sistema stesso.

\subsection{Le prestazioni}
L'altro problema emergente nello sviluppo di un programma antiplagio che non si limiti a confrontare la similarità tra una coppia di progetti, bensì effettui un controllo uno a molti o molti a molti, in cui si testano tutte le possibili coppie, sono le prestazioni. 
%
Infatti, la maggioranza delle tecniche e degli algoritmi per effettuare i confronti sono inefficienti in termini di tempo costo. 
%
Questo è in larga parte dovuto al fatto che la misurazione della somiglianza tra una coppia di sorgenti, nella gran parte degli algoritmi noti, ha una complessità almeno quadratica nel numero delle istanze delle sue rappresentazioni, e che, per ogni valutazione, il numero di confronti da effettuare è tipicamente elevato: detto $N$ il numero di progetti, volendo confrontare tutte le coppie di progetti tra loro, dovrebbero essere eseguite $\frac{N(N-1)}{2}$ comparazioni.

Questo problema è acuito dal fatto che i progetti \textit{software} stanno diventando sempre più complessi e si hanno a disposizione una sempre maggior quantità di dati da dover processare.

Per questa ragione vengono sfruttate tecniche di parallelizzazione e devono essere adottate strategie di ottimizzazione in grado di ridurre il numero di confronti da effettuare e, quindi, diminuire il tempo di esecuzione.
%
Per farlo, si utilizzano tecniche euristiche che permettono di determinare il grado di somiglianza dei sorgenti senza dover effettivamente eseguire il confronto.

Va da sé che l'utilizzo di tali tecniche impatta inevitabilmente la sensibilità del sistema: una stima errata, a monte, della somiglianza di due sorgenti può portare a non effettuare alcun confronto tra di questi e quindi a non individuare possibili plagi. 
%
Questo si verifica soprattutto nei casi in cui l'ottimizzazione è molto marcata e si riduce in modo eccessivo l'insieme dei sorgenti su cui effettuare il confronto, rendendo di fatto svantaggioso l'impiego di tali tecniche.

Il bilanciamento tra le prestazioni e l'efficacia del sistema è, dunque, di fondamentale importanza.

\todo{spiegare cosa esiste e perché serve che sia automatico}

\section{Stato dell'arte}

\todo{Forse da mettere altrove i paragrafi seguenti}
% preso spunto da "Current trends in source code analysis, plagiarism detection and issues of analysis big datasets" -- si deve citare??
Il codice sorgente non è nient'altro che un file di testo scritto da sviluppatori, che deve essere compilato o interpretato e che, pertanto, si basa su regole sintattiche e grammaticali proprie del linguaggio di programmazione con cui è scritto che permettono a entrambi gli attori, il programmatore e il calcolatore, di "capirlo" ed elaborarlo.

Per questo motivo, se processare la struttura di un sorgente non presenta grandi difficoltà, processare il significato, ovvero l'idea e la logica sottesa al codice, costituisce una sfida più grande, se non altro perché entra in gioco la competenza dello sviluppatore e la sua esperienza nella scrittura di codice "pulito".

Poiché il problema è complesso, gli attuali metodi di analisi non aspirano a risolvere il problema \textit{in toto}, ma analizzano il codice sorgente utilizzando un particolare "punto di vista": alcuni lo analizzano dal punto di vista del programmatore, cercando di comprenderne il significato, altri la loro struttura.

% Possiamo classificare le tecniche di analisi in tre approcci: 

% Il primo si basa sull'analisi del codice come mero testo: si presume che siano rispettate le convenzioni e il codice contenga sufficienti informazioni che ne descrivano il significato e cercano di estrarre solo queste significative informazioni aggiuntive.

% Il livello successivo è simile al precedente con la differenza che non esplora il significato del testo dal punto di vista del programmatore, bensì dal punto di vista del calcolatore, che "vede" il codice come una sequenza di comandi, ciascuno con il proprio significato nel contesto della grammatica del linguaggio.

% L'ultimo e terzo livello riguarda l'analisi del modello del codice sorgente.

In generale, come già accennato nel \todo{ref?}, la maggior parte dei sistemi automatici d'identificazione di plagi lavorano in due fasi consecutive: prima il codice sorgente viene analizzato e viene generata una rappresentazione intermedia, poi si effettua il confronto dei sorgenti sulle rappresentazioni intermedie.

Nei primi anni in cui l'esigenza di trovare un sistema automatico per la rilevazione di plagi ha preso piede, la principale tecnica di rilevamento era basata interamente sul confronto delle stringhe di cui si componeva il sorgente. 
%
Questo è un metodo è molto semplice, ma è fortemente sensibile al riordino delle istruzioni, nonché all'aggiunta di nuovo codice.

Con lo sviluppo della tecnologia, molti ricercatori hanno fatto progressi in questo campo e proposto molti algoritmi negli ultimi anni, formando gradualmente tre popolari famiglie di tecniche: \textbf{\textit{structure-based}}, \textbf{\textit{attribute-based}}, \textbf{\textit{hybrid detection}}. \todo{citazione?}

\subsection{Analisi \textit{structure-based}}

Le analisi \textit{structure-based} si basano, come suggerisce il nome, sulla struttura dei codici sorgenti.

\subsubsection{Analisi lessicale}
Tra tutte, la tecnica più usata consiste nell'analisi lessicale (\textbf{\textit{lexical analysis}} o \textbf{\textit{tokenization}} in inglese) del codice sorgente, che consiste nel convertire la sequenza di caratteri di cui è composto il programma in una sequenza di \textit{token}.
%
Un \textit{token} è una sequenza di caratteri che costituisce un'unità fondamentale nella grammatica del linguaggio ed è strutturato come una coppia \textit{nome} - \textit{valore}.
%
Alcuni possibili esempi sono riportati in \Cref{table:token-examples}.

\begin{itemize}
    \item \textit{identifier}: una stringa di lettere e numeri che iniziano con una lettera (usato per rappresentare i nomi scelti dai programmatori);
    \item \textit{keyword}: stringa per rappresentare i nomi dedicati nella sintassi del linguaggio;
    \item \textit{separator}: caratteri delimitatori e di punteggiatura;
    \item \textit{comment}: blocco di commenti.
\end{itemize}

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|} 
        \hline
        \textbf{Nome} & \textbf{Esempi di valori} \\ [0.5ex] 
        \hline\hline
        \textit{identifier} & \texttt{x}, \texttt{name}, \texttt{color} \\ 
        \hline
        \textit{keyword} & \texttt{if}, \texttt{for}, \texttt{return} \\
        \hline
        \textit{separator} & \texttt{\{}, \texttt{\}}, \texttt{(}, \texttt{;} \\
        \hline
        \textit{comment} & \texttt{/* This is a sample comment */} \\
        \hline
    \end{tabular}
    \caption{Esempi di possibili coppie nome-valore di \textit{token} comuni.}
    \label{table:token-examples}
\end{table}

L'analisi lessicale rappresenta il primo stadio della struttura di un compilatore ed è eseguita da programmi denominati \textbf{\textit{lexer}}. 
%
Questi sono generati in maniera dichiarativa a partire da generatori di \textit{lexer} (\textbf{\textit{lexer generator}}) che, presi in input più automa a stati finiti, espressi per mezzo di espressioni regolari che definiscono in maniera formale la grammatica del linguaggio, generano il codice che implementa l'algoritmo di analisi lessicale. 
% https://www.antlr.org ??
% esempio di FA ed espressione regolare

Attraverso questo approccio, quindi, ogni programma viene trasformato in una sequenza di \textit{token}, uno per ciascun elemento di base del linguaggio che si vuole valorizzare: le sezioni di codice non rilevanti ai fini della comparazione possono essere escluse, cioè non viene generato alcun \textit{token} per questi elementi.

% \lstinputlisting[
% 	float,
% 	language=Java,
% 	caption={Una semplice classe per mostrare il processo di \textit{tokenizzazione}},
% 	label={lst:testanalysis},
% ]{resources/code/TestAnalysis.java}

% \lstinputlisting[
% 	float,
% 	caption={La sequenza di \textit{token} generati a partire dal codice del \Cref{lst:testanalysis}},
% 	label={lst:tokensequence},
% ]{resources/code/AnalyzedTestAnalysis.txt}

% Nel \Cref{lst:tokensequence} è mostrata la sequenza di \textit{token} generata a partire dalla classe presentata nel \Cref{lst:testanalysis}.
% %
% Si noti che le dichiarazioni di \texttt{import} e dei \texttt{package}, così come il blocco di documentazione, non vengono considerati. 
% %
% Questo li rende insensibili contro le modifiche agli identificatori, ma non al riordino delle istruzioni.

Il risultato che si ottiene è una versione condensata e semplificata del sorgente, con un vocabolario ristretto.

Questo approccio rende il sistema sufficientemente robusto contro semplici tecniche di \textit{refactoring}, come la modifica degli identificatori, corrispondente al secondo livello della tassonomia di Faidhi \& Robinson (\Cref{img:01-levels-of-plagiarism}).

Tuttavia, bisogna evidenziare come l'efficacia della \textit{tokenizzazione} dipende dall'insieme di \textit{token} che si decide di usare.
%
Consideriamo, a puro scopo esemplificativo, il caso delle \textit{keyword} dedicate a rappresentare un intero in Java.
%
Come sappiamo, un intero è rappresentabile con diversi tipi di dato; a seconda delle esigenze di memoria, infatti, si potrebbe usare, considerando solo i tipi di dato primitivo e tralasciando quelli \textit{boxed}, un \texttt{byte}, piuttosto che uno \texttt{short}, un \texttt{int} o un \texttt{long}. 
%
Un insieme "stringente" di \textit{token} potrebbe rappresentare ciascuno di questi tipi con un proprio \textit{token}.
%
D'altro canto, un set di \textit{token} "lasco" potrebbe rappresentare tutti e quattro i tipi di dato sopra citati con un unico \textit{token}, riconoscendo che tutti e quattro possono servire, nella grande maggioranza dei casi, allo stesso stesso scopo.
%
Pertanto un insieme di \textit{token} "lasco" aiuta il sistema a riconoscere e catalogare come equivalenti tipi di dato diversi e fornire quindi una resilienza alle tecniche di rifattorizzazione.
% quale tipo? 3?

In seguito, la sequenza di \textit{token} generata viene confrontata con algoritmi di \textit{string matching}. 
%
Tra i due più conosciuti vi sono \textbf{\textit{Winnowing}} e \textbf{\textit{Running-Karp-Rabin Greedy String Tiling (RKR-GST)}}, che tende a migliorare la precisione, a discapito dell'efficienza. 

\textit{Winnowing} costituisce un miglioramento del metodo \textit{n-grams} e consiste nel suddividere il documento in una lista di sotto-strighe di lunghezza $n$ e  usare una funzione di \textit{hashing} per selezionare solo un sottoinsieme rappresentativo di tali sottosequenze del documento da usare come impronta digitale dello stesso (i cosiddetti \textit{n-grams fingerprinting}).

\textit{Running-Karp-Rabin Greedy String Tiling (RKR-GST)} costituisce l'altra popolare alternativa a \textit{Winnowing}, cercando di aumentare la precisione a discapito dell'efficienza. 
%
Esso incorpora, di fatto, due algoritmi.
%
\textit{Greedy String Tiling (GST)} è l'algoritmo che trova la massima sottosequenza comune in due stringhe.
%
\textit{Running-Karp-Rabin (RKR)} è l'algoritmo per la ricerca rapida di sottosequenze comuni e trova tutte le occorrenze di una stringa $P$ all'interno di una stringa più lunga $T$ effettuando l'\textit{hashing} di tutte le stringhe di lunghezza $|P|$ e confrontandole con gli \textit{hash} di $P$.
%
I due algoritmi cooperano in questo modo: \textit{RKR} è eseguito su due programmi.
%
Per ogni sottosequenza comune identificata da \textit{RKR}, \textit{GST} è eseguito per estendere il \textit{match} oltre i confini del \textit{hash value}.

\subsubsection{Analisi basata su un modello}
Invece di utilizzare la mera sequenza di \textit{token} generata dal \textit{lexer} possono essere generate delle strutture e dei modelli più complessi.

Il più diffuso è l'\textbf{albero sintattico} (o \textit{abstract syntax tree} in inglese, abbreviato AST).

\dots

Program Dependency Graph

\subsection{Analisi \textit{attribute-based}}
Nonostante l'efficienza delle tecniche di analisi strutturale descritte precedentemente, il loro punto debole si riscontra nelle prestazioni. 
%
Per far fronte a questo problema sono state storicamente introdotte nuove tecniche, dette \textit{attribute-based}, in quanto determinano il grado di similarità tra due sorgenti sulla base delle loro \dots

\subsection{\textit{Hybrid detection}}

\subsection{Quale tecnica scegliere?}
In conclusione, scegliere quali di questi approcci scegliere è complesso, perché difficili da confrontare tra loro: la maggior parte di queste tecniche viene valutata utilizzando il proprio \textit{set} di dati, che raramente sono resi pubblicamente accessibili \cite{karnalim-budi-toba-joy-2019}.

In conclusione, bisogna rendersi conto che, a prescindere dal grado di sofisticatezza della tecnica che si utilizza, è sempre possibile che si verifichi un plagio non rilevabile.
%
Da bilanciare le risorse investite nell'individuazione del plagio e i rendimenti decrescenti di trovare i pochi, se non nessuno, casi difficili da rilevare \cite{joy-99}.


