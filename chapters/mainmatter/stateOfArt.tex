% ! TeX root = ../../thesis.tex
\chapter{Stato dell'arte}
\label{chapter:stateOfArt}
\todo{Da completare}
In questo capitolo si passa in rassegna lo stato dell'arte sulle tecniche per l'analisi del codice sorgente e l'individuazione delle parti potenzialmente plagiate.
%
Dopo una breve visione d'insieme sono presentate le principali tre famiglie di tecniche impiegate in questo contesto, ponendo in evidenza vantaggi e svantaggi di ciascuna.
%
Infine, un ultimo paragrafo è dedicato al riepilogo e ad alcune considerazioni su quale metodo scegliere.

\section{Visione d'insieme}
% preso spunto da "Current trends in source code analysis, plagiarism detection and issues of analysis big datasets" -- si deve citare??
Il codice sorgente non è nient'altro che un file di testo scritto da sviluppatori, che deve essere compilato o interpretato e che, pertanto, si basa su regole sintattiche e grammaticali proprie del linguaggio di programmazione con cui è scritto che permettono a entrambi gli attori, il programmatore e il calcolatore, di "capirlo" ed elaborarlo.

Per questo motivo, se processare la struttura di un sorgente non presenta grandi difficoltà, processare il significato, ovvero l'idea e la logica sottesa al codice, costituisce una sfida più grande, se non altro perché entra in gioco la competenza dello sviluppatore e la sua esperienza nella scrittura di codice "pulito".

Poiché il problema è complesso, gli attuali metodi di analisi non aspirano a risolvere il problema \textit{in toto}, ma applicano il principio di decomposizione del problema e approcciano al codice sorgente da un particolare punto di vista: alcuni analizzano il codice dal punto di vista del programmatore, cercando di comprenderne il significato, altri la loro struttura.

% Possiamo classificare le tecniche di analisi in tre approcci: 

% Il primo si basa sull'analisi del codice come mero testo: si presume che siano rispettate le convenzioni e il codice contenga sufficienti informazioni che ne descrivano il significato e cercano di estrarre solo queste significative informazioni aggiuntive.

% Il livello successivo è simile al precedente con la differenza che non esplora il significato del testo dal punto di vista del programmatore, bensì dal punto di vista del calcolatore, che "vede" il codice come una sequenza di comandi, ciascuno con il proprio significato nel contesto della grammatica del linguaggio.

% L'ultimo e terzo livello riguarda l'analisi del modello del codice sorgente.

In generale, come già accennato nel \Cref{chapter:introduction}, la maggior parte dei sistemi automatici d'identificazione di plagi lavorano in due fasi consecutive: prima il codice sorgente viene analizzato e viene generata una rappresentenzazione intermedia, poi si effettua il confronto dei sorgenti sulle rappresentazioni intermedie.

\section{Tecniche di analisi}

Le tecniche di analisi possono essere classificate in tre cataegorie: \textbf{\textit{structure-based}}, \textbf{\textit{attribute-based}}, \textbf{\textit{hybrid detection}}.
% citazione?

\subsection{Analisi \textit{structure-based}}

\subsubsection{Analisi lessicale}
Tra tutte, la tecnica più usata consiste nell'analisi lessicale (\textbf{\textit{lexical analysis}} o \textbf{\textit{tokenization}} in inglese) del codice sorgente, che consiste nel convertire la sequenza di caratteri di cui è composto il programma in una sequenza di \textit{token}.
%
Un \textit{token} è una sequenza di caratteri che costituisce un'unità fondamentale nella grammatica del linguaggio ed è strutturato come una coppia \textit{nome} - \textit{valore}.
%
Alcuni possibili esempi sono riportati in \Cref{table:token-examples}.

\begin{itemize}
    \item \textit{identifier}: usato per rappresentare i nomi scelti dai programmatori ();
    \item \textit{keyword}: usato per i nomi dedicati nella sintassi del linguaggio;
    \item \textit{separator}: usato per delimitatori e i caratteri di punteggiatura;
    \item \textit{comment}: usato per un blocco di commenti.
\end{itemize}

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|} 
        \hline
        \textbf{Nome} & \textbf{Esempi di valori} \\ [0.5ex] 
        \hline\hline
        \textit{identifier} & \texttt{x}, \texttt{name}, \texttt{color} \\ 
        \hline
        \textit{keyword} & \texttt{if}, \texttt{for}, \texttt{return} \\
        \hline
        \textit{separator} & \texttt{\{}, \texttt{\}}, \texttt{(}, \texttt{;} \\
        \hline
        \textit{comment} & \texttt{/* This is a sample comment */} \\
        \hline
    \end{tabular}
    \caption{Esempi di possibili coppie nome-valore di \textit{token} comuni.}
    \label{table:token-examples}
\end{table}

L'analisi lessicale rappresenta il primo stadio della struttura di un compilatore ed è eseguita da programmi denominati \textbf{\textit{lexer}}. 
%
Questi sono generati in maniera dichiarativa a partire da generatori di \textit{lexer} (\textbf{\textit{lexer generator}}) che, preso in input più automa a stati finiti, espressi per mezzo di espressioni regolari che definiscono in maniera formale la grammatica del linguaggio, generano il codice che implementa l'algoritmo di analisi lessicale. 
% https://www.antlr.org ??

Attraverso questo approccio, quindi, ogni programma viene trasformato in una sequenza di \textit{token}, uno per ciascun elemento di base del linguaggio che si vuole valorizzare: i blocchi di commenti o documentazione, gli \texttt{import} e altre sezioni di codice non rilevanti ai fini della comparazione possono essere esclusi, cioè non viene generato alcun token per questi elementi.

\dots

\subsubsection{Analisi basata su un modello}

\subsection{Analisi \textit{attribute-based}}

\subsection{\textit{Hybrid detection}}

\subsection{Quale approccio scegliere?}
In conclusione, scegliere quali di questi approcci scegliere è complesso, perché difficili da confrontare tra loro: la maggior parte di queste tecniche viene valutata utilizzando il proprio \textit{set} di dati, che raramente sono resi pubblicamente accessibili \cite{karnalim-budi-toba-joy-2019}.

In conclusione, bisogna rendersi conto che, a prescindere dal grado di sofisticatezza della tecnica che si utilizza, è sempre possibile che si verifichi un plagio non rilevabile.
%
Da bilanciare le risorse investite nell'individuazione del plagio e i rendimenti decrescenti di trovare i pochi, se non nessuno, casi difficili da rilevare \cite{joy-99}.


