% ! TeX root = ../../thesis.tex
\chapter{Implementazione}
\label{chapter:implementation}
In questo capitolo vengono affrontati gli aspetti implementativi del sistema, descrivendo le tecnologie e i paradigmi utilizzati.

\vspace*{0.5cm}

La tecnica impiegata nel sistema appartiene alla famiglia di tecniche \textit{structure-based} e si compone macroscopicamente di tre fasi, schematizzate in \Cref{img:03-system-overview}:
\begin{enumerate}
	\item \textbf{Analisi}: i sorgenti sono \textit{parsati}, preprocessati e \textit{tokenizzati};
	\item Una fase opzionale di \textbf{filtraggio};
	\item \textbf{Rilevamento} delle somiglianze.
\end{enumerate}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{resources/img/03-system-overview.pdf}
    \caption{Visione d'insieme delle fasi della tecnica impiegata nel sistema in uso.}
    \label{img:03-system-overview}
\end{figure}

Di seguito ciascuna delle tre viene approfondita.

\section{Tecnica di analisi}
Il primo passo consiste nell'effettuare il \textit{parsing} dei sorgenti, affidato alla libreria JavaParser\footnote{\url{https://javaparser.org/}}.
%
JavaParser è una libreria \textit{open source} che permette di effettuare il \textit{parsing} di codice sorgente scritto in linguaggio Java, fornendo comodi meccanismi per l'analisi e la manipolazione dello stesso.

Il risultato del \textit{parsing} è un albero sintattico equivalente a quello mostrato in \Cref{img:01-ast} che rappresenta la struttura dei sorgenti.

Tuttavia, nonostante la generazione dell'albero sintattico sollevi dalla responsabilità di eliminare dal sorgente \textit{token} superflui, come gli spazi e i punti e virgola, in quanto naturalmente modellati dalla struttura stessa dell'albero, tale AST contiene ancora informazioni sovrabbondanti, come le dichiarazioni di \texttt{import} e dei \texttt{package}.
%
Per questo motivo è necessario una fase intermedia di \textit{preprocessing} in cui l'albero viene “sfoltito”. In particolare, in questa fase l'albero viene visitato e, oltre a rimuove le dichiarazioni suddette, sono rimosse anche le funzioni \texttt{hashCode()}, \texttt{equals()} e \texttt{toString()}.
%
Queste, infatti, nella maggioranza dei casi, vengono automaticamente generati dall'\textit{IDE} e non sono rappresentativi della logica dei sorgenti.

A seguire avviene la conversione del codice sorgente in una sequenza di \textit{token}.
%
Si noti che la fase di \textit{tokenizzazione} vera e propria descritta nella \Cref{01-tokenization} è già stata eseguita internamente dal \textit{parser} di JavaParser i cui \textit{token} sono quelli presenti nell'albero.
%
Tali \textit{token}, tuttavia, rappresentano in modo molto specifico la struttura del programma: ...
%
Come descritto nella \Cref{01-tokenization} l'obiettivo è creare invece un insieme di \textit{token} "lasco" che raggruppi tipi di \textit{token} equivalenti a livello semantico.

A questo scopo, l'albero sintattico preprocessato viene visitato e, per ogni nodo, si emette un \textit{token}, con le relative informazioni circa la sua posizione nel sorgente, o meno a seconda sia una dichiarazione semanticamente rilevante.

In particolare, è stato costruito un file di configurazione \textit{Yaml}\footnotetext{Linguaggio, \textit{superset} di Json, per la serializzazione di dati che viene impiegato per la scrittura di file di configurazione: \url{https://yaml.org/}.} (\Cref{lst:token-config-file}) in cui sono elencati i tipi di dichiarazioni rilevanti, eventualmente aggregando tra loro dichiarazione semanticamente simili e che potrebbero essere facilmente cambiate per offuscare la copiatura.
%
Ad esempio, sono state aggregate sotto un unico tipo \texttt{loop-stmt} tutti i costrutti che effettuano un ciclo.
%
In questo modo un cambio sintattico di tipo non sarà sufficiente ad aggirare il sistema perché verrà generato lo stesso tipo di \textit{token}.
%
Si noti che questo approccio è molto flessibile e può essere "aggiustato" a piacimento nel caso sia necessario effettuare una \textit{tokenizzazione} con un insieme di \textit{token} più stringente.

\lstinputlisting[
 	language=yaml,
 	caption={Porzione del file di configurazione con la definizione dei tipi di \textit{token}},
 	label={lst:token-config-file},
]{resources/code/03-token-types.yml}

Il risultato dell'applicazione del processo sopra descritto al \Cref{lst:test-analysis} viene presentato nel \Cref{lst:result-tokenization}

\lstinputlisting[
 	caption={Risultato dell'analisi del \Cref{lst:test-analysis}},
 	label={lst:result-tokenization},
]{resources/code/03-AnalyzedTestAnalysis}

% vengono anche tolti i duplicati :)

\section{Filtraggio}
A seguito dell'analisi del codice sorgente e della generazione della sequenza di \textit{token} i sorgenti del \textit{corpus} possono essere filtrati, al fine di limitare il numero di progetti da dover confrontare.
%
Questo \textit{step} rappresenta uno snodo critico nella \textit{pipeline} di azione da eseguire in quanto scambia una frazione dell'efficacia del sistema in favore dell'efficienza: una stima fuorviante della similarità di due progetti può comportare l'esclusione dello stesso, con la conseguente perdita di sensibilità.
%
Per questo motivo la fase di filtraggio è \textit{opzionalmente} eseguita a discrezione dell'utente.

Come già presentato nella \Cref{01-tokenization}, il processo di filtraggio è preceduto da una fase d'indicizzazione in cui vengono aggregati i dati sotto forma di una struttura dati per mezzo della quale è possibile estrarre informazioni statistiche significative per la stima della similarità.

Nel sistema è attualmente stato implementato un indice equivalente a quello presentato in \Cref{table:token-indexing} a partire dal quale la similarità tra progetti è stata calcolata mediante la \textbf{similarità coseno}.
%
Essa è una metrica euristica per la misurazione della similutidine di due vettori effettuata calcolando il coseno del loro angolo, ampiamente utilizzata nel contesto dell'analisi testuale ed è definita come segue: 
\begin{equation}
	cosine\_similarity(A,B) = \frac{A \cdot B}{||A|| ||B||} 
		= \frac{\sum_{k=1}^{n} A(k) B(k)}{\sqrt{\sum_{k=1}^{n}A(k)^2 \cdot \sum_{k=1}^{n} B(k)^2}}
\end{equation}
dove $A$ e $B$ sono due vettori di attributi numerici a $n$ dimensioni.

In generale, il risultato della similarità è un valore compreso tra $-1$ e $1$ dove $-1$ indica che i due vettori sono \textit{anti}-correlati (hanno verso opposto), $1$ indica massima correlazione e $0$ un'assenza di correlazione (i due vettori sono ortogonali tra loro).

Nel nostro caso, il contenuto dei due vettori è la frequenza dei tipi di \textit{token} in cui il $k$-esimo elemento contiene il numero di volte in cui il tipo di \textit{token} numerato con $k$ ricorre nel sorgente, oppure $0$ se non presente.
%
Poiché le frequenze sono valori sempre positivi nel caso in esame si otterranno valori compresi tra $0$ e $1$, dove $1$ indica che i tipi di \textit{token} contenuti nelle due rappresentazioni sono gli stessi, presenti in egual numero, ma non necessariamente disposti nello stesso ordine, e $0$ indica che non c'è alcun tipo di \textit{token} comune.

A seguito della stima della similarità coseno, tutte le coppie di rappresentazioni la cui similarità è inferiore a un valore di soglia sono esclusi.
%
Tale valore è calcolato, seguendo quanto riportato in \cite{es-plag}, utilizzando la formula riportata in \Cref{eq:cosine-filtering-threshold}.

\begin{equation}
\label{eq:cosine-filtering-threshold}	
	threshold = sim_{min} + init_threshold \cdot (sim_{max} - sim_{min})
\end{equation}

dove $init_threshold$ è un valore compreso tra $0$ e $1$ (corrispondente al range $0-100$) e $sim_{max}$ e $sim_{min}$ sono rispettivamente la similarità coseno massima e minima risultante dalla comparazione di tutte le coppie.

\section{Rilevamento delle somiglianze}
\label{03-matching-algorithms}
Gli algoritmi impiegati per confrontare due sequenze di \textit{token} sono il \textit{Greedy String Tiling} e \textit{Running Karp-Rabin Matching}, che ne rappresenta una sua evoluzione, introdotti da M. Wise nel 1993 in \cite{wise-running-93}.
%
Sebbene questi algoritmi siano stati concepiti per lavorare su sequenze di stringhe, possono essere facilmente riadattati per operare su sequenze di \textit{token}.

Dette $A$ e $B$ due sequenze di \textit{token}, un algoritmo per misurare la similarità in questo dominio deve determinare una sottosequenza comune che abbia le seguenti proprietà:
\begin{itemize}
	\item ogni \textit{token} di $A$ può essere abbinato solo con esattamente un solo \textit{token} di $B$;
	\item le sottosequenze comuni devono essere trovate indipendentemente dalla loro posizione nel sorgente;
	\item le sottosequenze più lunghe sono preferite a quelle più piccole, in quanto le sottosequenze brevi è molto probabile rappresentino casi spuri.
\end{itemize}

L'algoritmo si compone principalmente di due fasi:
\begin{itemize}
	\item \textbf{Fase 1}: in questa fase, viene ricercata la corrispondenza più lunga. Questo è fatto grazie un triplo ciclo innestato: il primo itera sui token della sequenza più corta, denominata \textit{pattern}, il secondo compara ciascuno di questi con ogni \textit{token} della sequenza più lunga, denominata \textit{text}. Se i due \textit{token} corrispondono il ciclo più interno cerca di estendere il \textit{match} il più possibile (fermandosi non appena trova un \textit{token} che nelle due sequenze differisce).

	\item \textbf{Fase 2}: questa fase marca ciascun \textit{match} trovato nella fase precedente partendo da quello più lungo. Questo garantisce che ciascun \textit{token} venga usato per un solo \textit{match} e divenga indisponibile per i \textit{match} successivi (che hanno una minor lunghezza). Nella terminologia di \cite{wise-running-93} i \textit{match} i cui \textit{token} sono stati marcati sono denominati \textit{tile}.
\end{itemize}

Queste due fasi vengono ripetute fino a quando non vengono trovate più corrispondenze di lunghezza almeno \texttt{minimum\_match\_length}.
%
Tale valore è imposto per non generare troppe sequenze spurie di lunghezza irrisoria e garantire risultati migliori.
%
Giacché la lunghezza dei \textit{match} diminuisce, nel caso peggiore, di un'unità ad ogni iterazione è garantito che l'algoritmo termini.

Lo pseudocodice dell'algoritmo è presentato nel \Cref{lst:gst}.

\lstinputlisting[
	float,
	language=pseudocode,
 	caption={Pseudocodice dell'algoritmo \textit{Greedy String Tiling (GST)}. In accordo con la terminologia del \textit{paper} $P$ rappresenta il \textit{pattern} ovvero la sequenza da confrontare più corta, mentre $T$ il \textit{text} ovvero la sequenza tra le due più lunga.},
 	label={lst:gst},
]{resources/code/03-gst}

Questo algoritmo è dimostrato \cite{wise-running-93} essere ottimo in termini di massimizzazione della copertura delle stringhe.
%
Nonostante ciò, nel caso peggiore, ha una complessità $O(n^3)$ e pertanto è molto inefficiente.

Per far fronte a questo problema è stato ideato un nuovo algoritmo chiamato \textit{Running Karp Rabin Greedy String Tiling}.
%
L'idea su cui si fonda per velocizzare il confronto è impiegare una funzione di \textit{hashing}.
%
In particolare, il valore di \textit{hash} di ogni sottosequenza di lunghezza $s$ del \textit{pattern} viene confrontato con il valore di \textit{hash} di quelle del \textit{text}.
%
Laddove i due valori corrispondano, e solo in questo caso, le sottosequenze vengono confrontate \textit{token} per \textit{token} per assicurarsi che effettivamente siano uguali e non frutto di una collisione della funzione di \textit{hash}.

Nel \Cref{lst:rkr-scanpattern} viene mostrato lo pseudocodice della \textit{routine} che si occupa di effettuare questo confronto.
%
Come si può osservare, nelle righe 1-3 vengono calcolati i valori di \textit{hash} di tutte le sottosequenze (non marcate) di lunghezza $s$ del \textit{text} e vengono salvati in una \textit{hashtable}, una mappa con le corrispondenze sottosequenza di \textit{token} $-$ valore di \textit{hash}.
%
Lo stesso viene fatto per il \textit{pattern} con la differenza che, non appena calcolato il valore \textit{hash} per la sottosequenza considerata, si verifica se lo stesso sia già presente nella \textit{hashtable}.
%
In questo caso, infatti, potrebbe effettivamente esserci una corrispondenza e si procede verificando \textit{token} per \textit{token}.
%
Si noti che nei casi in cui la corrispondenza sia effettiva e non sia causata da un artefatto della funzione di \textit{hash}, il \textit{match} è esteso fino al primo \textit{token} non corrispondente, proprio come nel precedente algoritmo.

\lstinputlisting[
	float,
 	language=pseudocode,
 	caption={Pseudocodice routine \texttt{scanpattern} dell'algoritmo \textit{RKR-GST}},
 	label={lst:rkr-scanpattern},
]{resources/code/03-rkr-gst-scanpattern}

Il \Cref{lst:rkr-markarrays} presenta lo pseudocodice della \textit{routine} che effettua la marcatura dei \textit{match} individuati in \texttt{scanpattern}, corrispondente alla seconda fase dell'algoritmo precedente.
%
La principale differenza è...

\lstinputlisting[
	float,
 	language=pseudocode,
 	caption={markarrays},
 	label={lst:rkr-markarrays},
]{resources/code/03-rkr-gst-markarrays}

Infine, nel \Cref{lst:rkr-top-level} è mostrato l'\textit{entry-point} dell'algoritmo.
%
% s come viene scelto?
%

\lstinputlisting[
	float,
 	language=pseudocode,
 	caption={top level algorithm},
 	label={lst:rkr-top-level},
]{resources/code/03-rkr-gst-top-algorithm}

Sebbene la complessità di questo algoritmo sia dimostrato essere, nel caso peggiore, $O(n^2)$, nel caso medio la complessità è pressoché lineare.
%
Ciò migliora notevolmente le prestazioni rispetto all'algoritmo \textit{Greedy String Tiling}.

\section{Stima della similarità}

\section{Strumenti di sviluppo}

\subsection*{\textit{Kotlin}}
Il progetto è stato sviluppato interamente in \textit{Kotlin}, un linguaggio di programmazione \textbf{orientato agli oggetti} e \textbf{funzionale} \textit{open source}\footnote{\url{https://github.com/JetBrains/kotlin}} progettato e gestito da \textit{JetBrains}\footnote{\url{https://www.jetbrains.com/}} a partire dal 2010.
%
Si tratta di un linguaggio multipiattaforma compilato, tipato staticamente e  completamente interoperabile con \textit{Java} e la \textit{JVM} e \textit{Android}, applicabile in una vasta gamma di ambiti, dallo sviluppo \textit{server side} a quello di applicazioni mobili (attualmente è il linguaggio di riferimento per \textit{Android}, avendo surclassato Java).
%
Inoltre, oltre a Java e Android, \textit{Kotlin} può essere compilato in \textit{JavaScript}, consentendo di eseguire codice \textit{Kotlin} nel \textit{browser}.

L'obiettivo principale del linguaggio è fornire un'alternativa a Java più concisa, produttiva e sicura, adatta in tutti i contesti in cui Java è tutt'oggi utilizzato.
%
Infatti, essendo completamente compatibile con Java, sfrutta tutte le numerose libreria di Java, estendendole e garantendo le stesse \textit{performance}.

I tratti distintivi di \textit{Kotlin} sono certamente la sua espressività e concisione, che permettono di sviluppare codice che rivela l'intento senza oscurarlo con codice verboso per specificare come l'intento viene realizzato.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{resources/img/03-kotlincompilation.pdf}
    \caption{Processo di compilazione di \textit{Kotlin}.}
    \label{img:03-kotlin-compilation}
\end{figure}

\subsection*{Git e \textit{CI}}

\subsection*{Librerie esterne}

\subsection*{Controllo di qualità}
